import torch 
import argparse
import os
import datetime

from config import DATA, MODEL_DIR, PARAMS, SCALE_PARAMS, INFERENCE_DIR
from preprocessing import get_mapper
from train import build_model, get_model_path

if __name__ == "__main__":
    torch.manual_seed(42)
    # Set device
    device = torch.device(
        "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    )
    print(f"Using device: {device}")

    # argument parsing
    parser = argparse.ArgumentParser(description="Inference from DrakeGPT")
    parser.add_argument("--model", type=str, default="TransformerLM", help="Model to infer from")
    parser.add_argument("--scale", type=bool, default=False, help="Train scaled model")
    parser.add_argument("--length", type=int, default=1000, help="Number of characters to generate")

    args = parser.parse_args()

    # read data
    with open(DATA["input"], 'r', encoding='utf-8') as f:
        text = f.read()

    encode, decode, vocab_size = get_mapper(text)

    # instantiate model
    model, model_config = build_model(args.model, args.scale, PARAMS, SCALE_PARAMS, vocab_size, device)

    # load model
    model_path = get_model_path(MODEL_DIR, args.model, args.scale)
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model {args.model} not found in {MODEL_DIR}")
    model.load_state_dict(torch.load(model_path, map_location=device))

    # inference
    print(f"Generating {args.length} character text using {args.model}...")
    model.eval()

    idx = torch.zeros((1, 1), dtype=torch.long, device=device)
    pred = decode(model.generate(idx, max_new_tokens=args.length)[0].tolist())
    print(f"Song text generated by DrakeGPT:{pred}")

    # save the generated text 
    now = datetime.datetime.now()
    date = now.strftime("%Y%m%d")
    time = now.strftime("%H%M")
    model_name = args.model if not args.scale else f"{args.model}_scaled"
    filename = f"generation_{model_name}_{date}_{time}.txt"
    file_path = os.path.join(INFERENCE_DIR, filename)
    with open(file_path, 'w', encoding='utf-8') as file:
        file.write(pred)
    print(f"Generated text and saved to {file_path}")